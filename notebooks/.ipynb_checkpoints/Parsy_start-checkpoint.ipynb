{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text = '''{\n",
    "    \"glossary\": {\n",
    "        \"title\": \"example glossary\",\n",
    "\t\t\"GlossDiv\": {\n",
    "            \"title\": \"S\",\n",
    "\t\t\t\"GlossList\": {\n",
    "                \"GlossEntry\": {\n",
    "                    \"ID\": \"SGML\",\n",
    "\t\t\t\t\t\"SortAs\": \"SGML\",\n",
    "\t\t\t\t\t\"GlossTerm\": \"Standard Generalized Markup Language\",\n",
    "\t\t\t\t\t\"Acronym\": \"SGML\",\n",
    "\t\t\t\t\t\"Abbrev\": \"ISO 8879:1986\",\n",
    "\t\t\t\t\t\"GlossDef\": {\n",
    "                        \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\",\n",
    "\t\t\t\t\t\t\"GlossSeeAlso\": [\"GML\", \"XML\"]\n",
    "                    },\n",
    "\t\t\t\t\t\"GlossSee\": \"markup\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'glossary': {'title': 'example glossary', 'GlossDiv': {'title': 'S', 'GlossList': {'GlossEntry': {'ID': 'SGML', 'SortAs': 'SGML', 'GlossTerm': 'Standard Generalized Markup Language', 'Acronym': 'SGML', 'Abbrev': 'ISO 8879:1986', 'GlossDef': {'para': 'A meta-markup language, used to create markup languages such as DocBook.', 'GlossSeeAlso': ['GML', 'XML']}, 'GlossSee': 'markup'}}}}}\n"
     ]
    }
   ],
   "source": [
    "from sys import stdin\n",
    "\n",
    "from parsy import generate, regex, string\n",
    "\n",
    "whitespace = regex(r'\\s*') #\n",
    "\n",
    "lexeme = lambda p: p << whitespace\n",
    "lbrace = lexeme(string('{'))\n",
    "rbrace = lexeme(string('}'))\n",
    "lbrack = lexeme(string('['))\n",
    "rbrack = lexeme(string(']'))\n",
    "colon  = lexeme(string(':'))\n",
    "comma  = lexeme(string(','))\n",
    "true   = lexeme(string('true')).result(True)\n",
    "false  = lexeme(string('false')).result(False)\n",
    "null   = lexeme(string('null')).result(None)\n",
    "\n",
    "number = lexeme(\n",
    "    regex(r'-?(0|[1-9][0-9]*)([.][0-9]+)?([eE][+-]?[0-9]+)?')\n",
    ").map(float)\n",
    "\n",
    "string_part = regex(r'[^\"\\\\]+')\n",
    "\n",
    "string_esc = string('\\\\') >> (\n",
    "    string('\\\\')\n",
    "    | string('/')\n",
    "    | string('\"')\n",
    "    | string('b').result('\\b')\n",
    "    | string('f').result('\\f')\n",
    "    | string('n').result('\\n')\n",
    "    | string('r').result('\\r')\n",
    "    | string('t').result('\\t')\n",
    "    | regex(r'u[0-9a-fA-F]{4}').map(lambda s: chr(int(s[1:], 16)))\n",
    ")\n",
    "\n",
    "quoted = lexeme(string('\"') >> (string_part | string_esc).many().concat() << string('\"'))\n",
    "\n",
    "\n",
    "# Circular dependency between array and value means we use `generate` form here\n",
    "@generate\n",
    "def array():\n",
    "    yield lbrack\n",
    "    elements = yield value.sep_by(comma)\n",
    "    yield rbrack\n",
    "    return elements\n",
    "\n",
    "\n",
    "@generate\n",
    "def object_pair():\n",
    "    key = yield quoted\n",
    "    yield colon\n",
    "    val = yield value\n",
    "    return (key, val)\n",
    "\n",
    "\n",
    "json_object = lbrace >> object_pair.sep_by(comma).map(dict) << rbrace\n",
    "value = quoted | number | json_object | array | true | false | null\n",
    "json = whitespace >> value\n",
    "\n",
    "\n",
    "print(repr(json.parse(json_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "\n",
    "class LangLexer(Lexer):\n",
    "\n",
    "    # lexer\n",
    "\n",
    "    # main tokens - ID, keywords, data types, some funcs, like TYPEOF\n",
    "\n",
    "    tokens = {ID, INT, FLOAT, ASSIGN, STRING, LET,\n",
    "              IF, ELSE, EQEQ, SEP, NOTEQ, LESS,\n",
    "              GREATER, LESSEQ, GREATEREQ, NIL, WHILE,\n",
    "              FOR, FN, RETURN, LAMBDA, ARROW, TRUE, FALSE,\n",
    "              AND, OR, SHR, SHL, INC, DEC, PLUSASGN,\n",
    "              MINUSASGN, STARASGN, SLASHASGN, MODULOASGN,\n",
    "              ANDASGN, ORASGN, XORASGN, SHLASGN, SHRASGN,\n",
    "              IMPORT, STRUCT, INT_TYPE, FLOAT_TYPE, BOOL_TYPE,\n",
    "              LIST_TYPE, DICT_TYPE, STRING_TYPE, TYPEOF,\n",
    "              LEFTARROW, PIPE, CLASS, DOUBLECOLON}\n",
    "\n",
    "    # ignore tabs and comments\n",
    "\n",
    "    ignore = ' \\t'\n",
    "    ignore_comment_slash = r'//.*'\n",
    "\n",
    "    # one-symbol literals\n",
    "\n",
    "    literals = {'=', '+', '-', '/', '*',\n",
    "                '(', ')', ',', '{', '}',\n",
    "                '%', '[', ']', '!', '&',\n",
    "                '|', '^', '?', ':', '~',\n",
    "                '.'}\n",
    "\n",
    "    # assign of logical and assign operators\n",
    "\n",
    "    INC = r'\\+\\+'\n",
    "    DEC = r'--'\n",
    "    PIPE = r'\\|>'\n",
    "    PLUSASGN = r'\\+='\n",
    "    MINUSASGN = r'-='\n",
    "    STARASGN = r'\\*='\n",
    "    SLASHASGN = r'/='\n",
    "    MODULOASGN = r'%='\n",
    "    ANDASGN = r'&='\n",
    "    ORASGN = r'\\|='\n",
    "    XORASGN = r'^='\n",
    "    SHLASGN = r'<<='\n",
    "    SHRASGN = r'>>='\n",
    "    ARROW = r'=>'\n",
    "    LESSEQ = r'<='\n",
    "    GREATEREQ = r'>='\n",
    "    LEFTARROW = r'<-'\n",
    "    SHR = r'>>'\n",
    "    SHL = r'<<'\n",
    "    LESS = r'<'\n",
    "    GREATER = r'>'\n",
    "    NOTEQ = r'!='\n",
    "    EQEQ = r'=='\n",
    "    ASSIGN = r'='\n",
    "    SEP = r';'\n",
    "    DOUBLECOLON = r'::'\n",
    "\n",
    "    # keywords\n",
    "\n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    ID['let'] = LET\n",
    "    ID['if'] = IF\n",
    "    ID['else'] = ELSE\n",
    "    ID['nil'] = NIL\n",
    "    ID['while'] = WHILE\n",
    "    ID['for'] = FOR\n",
    "    ID['fn'] = FN\n",
    "    ID['return'] = RETURN\n",
    "    ID['lambda'] = LAMBDA\n",
    "    ID['true'] = TRUE\n",
    "    ID['false'] = FALSE\n",
    "    ID['and'] = AND\n",
    "    ID['or'] = OR\n",
    "    ID['import'] = IMPORT\n",
    "    ID['struct'] = STRUCT\n",
    "    ID['int'] = INT_TYPE\n",
    "    ID['float'] = FLOAT_TYPE\n",
    "    ID['string'] = STRING_TYPE\n",
    "    ID['bool'] = BOOL_TYPE\n",
    "    ID['list'] = LIST_TYPE\n",
    "    ID['dict'] = DICT_TYPE\n",
    "    ID['typeof'] = TYPEOF\n",
    "    ID['class'] = CLASS\n",
    "\n",
    "    @_(r'\\d+\\.\\d+')\n",
    "    def FLOAT(self, t):\n",
    "        # float numbers\n",
    "        t.value = float(t.value)\n",
    "        return t\n",
    "\n",
    "    @_(r'\\d+')\n",
    "    def INT(self, t):\n",
    "        # integer numbers\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    @_(r'\\\".*?(?<!\\\\)(\\\\\\\\)*\\\"')\n",
    "    def STRING(self, t):\n",
    "        # parsing the string type and cleaning it\n",
    "        t.value = t.value[1:-1]\n",
    "        t.value = t.value.replace(r\"\\n\", \"\\n\")\n",
    "        t.value = t.value.replace(r\"\\t\", \"\\t\")\n",
    "        t.value = t.value.replace(r\"\\\\\", \"\\\\\")\n",
    "        t.value = t.value.replace(r\"\\\"\", \"\\\"\")\n",
    "        t.value = t.value.replace(r\"\\a\", \"\\a\")\n",
    "        t.value = t.value.replace(r\"\\b\", \"\\b\")\n",
    "        t.value = t.value.replace(r\"\\r\", \"\\r\")\n",
    "        t.value = t.value.replace(r\"\\t\", \"\\t\")\n",
    "        t.value = t.value.replace(r\"\\v\", \"\\v\")\n",
    "        return t\n",
    "\n",
    "    @_(r'\\n+')\n",
    "    def ignore_newline(self, t):\n",
    "        self.lineno += len(t.value)\n",
    "\n",
    "    def error(self, t):\n",
    "        print(\"Illegal character '%s' on line %d\" % (t.value[0], self.lineno))\n",
    "        self.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "lex = LangLexer()\n",
    "\n",
    "\n",
    "from parsy import digit, generate, match_item, regex, string, success, test_item\n",
    "\n",
    "\n",
    "'''def lexer(code):\n",
    "    \n",
    "    whitespace = regex(r'\\s*')\n",
    "    integer = digit.at_least(1).concat().map(int)\n",
    "    float_ = (\n",
    "        digit.many() + string('.').result(['.']) + digit.many()\n",
    "    ).concat().map(float)\n",
    "    parser = whitespace >> ((\n",
    "        float_ | integer  | regex(r'[()*/+-]')\n",
    "    ) << whitespace).many()\n",
    "    return parser.parse(code)'''\n",
    "\n",
    "\n",
    "def eval_tokens(tokens):\n",
    "\n",
    "    lparen = match_item('(')\n",
    "    rparen = match_item(')')\n",
    "\n",
    "    @generate\n",
    "    def additive():\n",
    "        res = yield multiplicative\n",
    "        sign = match_item('+') | match_item('-')\n",
    "        while True:\n",
    "            operation = yield sign | success('')\n",
    "            if not operation:\n",
    "                break\n",
    "            operand = yield multiplicative\n",
    "            if operation == '+':\n",
    "                res += operand\n",
    "            elif operation == '-':\n",
    "                res -= operand\n",
    "        return res\n",
    "\n",
    "    @generate\n",
    "    def multiplicative():\n",
    "        res = yield simple\n",
    "        op = match_item('*') | match_item('/')\n",
    "        while True:\n",
    "            operation = yield op | success('')\n",
    "            if not operation:\n",
    "                break\n",
    "            operand = yield simple\n",
    "            if operation == '*':\n",
    "                res *= operand\n",
    "            elif operation == '/':\n",
    "                res /= operand\n",
    "        return res\n",
    "\n",
    "    @generate\n",
    "    def number():\n",
    "        sign = yield match_item('+') | match_item('-') | success('+')\n",
    "        value = yield test_item(\n",
    "            lambda x: isinstance(x, (int, float)), 'number')\n",
    "        return value if sign == '+' else -value\n",
    "\n",
    "    expr = additive\n",
    "    simple = (lparen >> expr << rparen) | number\n",
    "\n",
    "    return expr.parse(tokens)\n",
    "\n",
    "\n",
    "def simple_eval(expr):\n",
    "    text = lex.tokenize(expr)\n",
    "    toks = [token.value for token in text]\n",
    "    return eval_tokens(toks)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(simple_eval(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsParser:\n",
    "\n",
    "    def eval_tokens(self, tokens):\n",
    "\n",
    "        lparen = match_item('(')\n",
    "        rparen = match_item(')')\n",
    "\n",
    "        @generate\n",
    "        def additive():\n",
    "            res = yield multiplicative\n",
    "            sign = match_item('+') | match_item('-')\n",
    "            while True:\n",
    "                operation = yield sign | success('')\n",
    "                if not operation:\n",
    "                    break\n",
    "                operand = yield multiplicative\n",
    "                if operation == '+':\n",
    "                    res += operand\n",
    "                elif operation == '-':\n",
    "                    res -= operand\n",
    "            return res\n",
    "\n",
    "        @generate\n",
    "        def multiplicative():\n",
    "            res = yield simple\n",
    "            op = match_item('*') | match_item('/')\n",
    "            while True:\n",
    "                operation = yield op | success('')\n",
    "                if not operation:\n",
    "                    break\n",
    "                operand = yield simple\n",
    "                if operation == '*':\n",
    "                    res *= operand\n",
    "                elif operation == '/':\n",
    "                    res /= operand\n",
    "            return res\n",
    "\n",
    "        @generate\n",
    "        def number():\n",
    "            sign = yield match_item('+') | match_item('-') | success('+')\n",
    "            value = yield test_item(\n",
    "                lambda x: isinstance(x, (int, float)), 'number')\n",
    "            return value if sign == '+' else -value\n",
    "\n",
    "        expr = additive | multiplicative\n",
    "        simple = (lparen >> expr << rparen) | number\n",
    "\n",
    "        return expr.parse(tokens)\n",
    "\n",
    "\n",
    "    def simple_eval(self, expr, lex):\n",
    "        text = lex.tokenize(expr)\n",
    "        toks = [token.value for token in text]\n",
    "        print(toks)\n",
    "        return self.eval_tokens(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 1, '+', 2, ')', '/', '(', 3, '+', 7, ')']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex = LangLexer()\n",
    "expression = '(1 + 2) / (3 + 7)'\n",
    "cs_parser = CsParser()\n",
    "cs_parser.simple_eval(expression, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpParser:\n",
    "\n",
    "    def eval_tokens(self, tokens):\n",
    "\n",
    "        lparen = match_item('(')\n",
    "        rparen = match_item(')')\n",
    "\n",
    "        @generate\n",
    "        def additive():\n",
    "            res = yield multiplicative\n",
    "            sign = match_item('+') | match_item('-')\n",
    "            while True:\n",
    "                operation = yield sign | success('')\n",
    "                if not operation:\n",
    "                    break\n",
    "                operand = yield multiplicative\n",
    "                if operation == '+':\n",
    "                    return ('-', res, operand)\n",
    "                elif operation == '-':\n",
    "                    return ('-', res, operand)\n",
    "\n",
    "        @generate\n",
    "        def multiplicative():\n",
    "            res = yield simple\n",
    "            op = match_item('*') | match_item('/')\n",
    "            while True:\n",
    "                operation = yield op | success('')\n",
    "                if not operation:\n",
    "                    break\n",
    "                operand = yield simple\n",
    "                if operation == '*':\n",
    "                    return ('*', res, operand)\n",
    "                elif operation == '/':\n",
    "                    return ('/', res, operand)\n",
    "\n",
    "        @generate\n",
    "        def number():\n",
    "            sign = yield match_item('+') | match_item('-') | success('+')\n",
    "            value = yield test_item(\n",
    "                lambda x: isinstance(x, (int, float)), 'number')\n",
    "            return value if sign == '+' else -value\n",
    "\n",
    "        expr = additive\n",
    "        simple = (lparen >> expr << rparen) | number\n",
    "\n",
    "        return expr.parse(tokens)\n",
    "\n",
    "\n",
    "    def simple_eval(self, expr, lex):\n",
    "        text = lex.tokenize(expr)\n",
    "        toks = [token.value for token in text]\n",
    "        print(toks)\n",
    "        return self.eval_tokens(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 1, '+', 2, ')', '/', '(', 3, '+', 7, ')']\n"
     ]
    }
   ],
   "source": [
    "lex = LangLexer()\n",
    "expression = '(1 + 2) / (3 + 7)'\n",
    "exp_parser = ExpParser()\n",
    "a = exp_parser.simple_eval(expression, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

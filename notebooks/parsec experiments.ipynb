{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_chars = letter() | space() |  one_of('/.,:\"[]') | digit()\n",
    "parser =  many(many(possible_chars) + string(\"<\") >> mark(many(possible_chars)) << string(\">\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_str = \"/\"\n",
    "parser.parse(ex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = \"\"\"\n",
    "<kv>\n",
    "  key1: \"string\"\n",
    "  key2: 1.00005\n",
    "  key3: [1,2,3]\n",
    "</kv>\n",
    "<csv>\n",
    "date,windspeed,direction\n",
    "20190805,22,NNW\n",
    "20190805,23,NW\n",
    "20190805,20,NE\n",
    "</csv>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsec import *\n",
    "\n",
    "spaces = regex(r'\\s*', re.MULTILINE)\n",
    "name = regex(r'[_a-zA-Z][_a-zA-Z0-9]*')\n",
    "\n",
    "tag_start = spaces >> string('<') >> name << string('>') << spaces\n",
    "tag_stop = spaces >> string('</') >> name << string('>') << spaces\n",
    "\n",
    "@generate\n",
    "def header_kv():\n",
    "    key = yield spaces >> name << spaces\n",
    "    yield string(':')\n",
    "    value = yield spaces >> regex('[^\\n]+')\n",
    "    return {key: value}\n",
    "\n",
    "@generate\n",
    "def header():\n",
    "    tag_name = yield tag_start\n",
    "    values = yield sepBy(header_kv, string('\\n'))\n",
    "    tag_name_end = yield tag_stop\n",
    "    assert tag_name == tag_name_end\n",
    "    return {\n",
    "        'type': 'tag',\n",
    "        'name': tag_name,\n",
    "        'values': values\n",
    "    }\n",
    "\n",
    "'''@generate\n",
    "def body():\n",
    "    tag_name = yield tag_start\n",
    "    values = yield sepBy(sepBy1(regex(r'[^\\n<,]+'), string(',')), string('\\n'))\n",
    "    tag_name_end = yield tag_stop\n",
    "    assert tag_name == tag_name_end\n",
    "    return {\n",
    "        'type': 'tag',\n",
    "        'name': tag_name,\n",
    "        'values': values\n",
    "    }'''\n",
    "\n",
    "parser = header #+ body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'tag',\n",
       " 'name': 'kv',\n",
       " 'values': [{'key1': '\"string\"'}, {'key2': '1.00005'}, {'key3': '[1,2,3]'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-0d2114b58a94>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-0d2114b58a94>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from parsec import\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from parsec import *\n",
    "from parsec import \n",
    "\n",
    "# ignore \n",
    "whitespace = regex(r'\\s+', re.MULTILINE)\n",
    "comment = regex(r';.*')\n",
    "ignore = many((whitespace | comment))\n",
    "\n",
    "\n",
    "lexeme = lambda p: p << ignore  \n",
    "\n",
    "lparen = lexeme(string('('))\n",
    "rparen = lexeme(string(')'))\n",
    "number = lexeme(regex(r'\\d+')).parsecmap(int)\n",
    "symbol = lexeme(regex(r'[\\d\\w_-]+'))\n",
    "true = lexeme(string('#t')).result(True)\n",
    "\n",
    "false = lexeme(string('#f')).result(False)\n",
    "\n",
    "op = lexeme(regex(r'[\\+\\-*/]'))\n",
    "\n",
    "\n",
    "atom = op | number | symbol | (true ^ false)\n",
    "\n",
    "\n",
    "@generate('a form')\n",
    "def form():\n",
    "    '''Parse expression within a pair of parenthesis.'''\n",
    "    yield lparen\n",
    "    es = yield many(expr)\n",
    "    yield rparen\n",
    "    return es\n",
    "\n",
    "\n",
    "@generate\n",
    "def quote():\n",
    "    '''Parse expression after a quote symbol.'''\n",
    "    yield string(\"'\")\n",
    "    e = yield expr\n",
    "    return ['quote', e]\n",
    "\n",
    "expr = atom | form | quote\n",
    "\n",
    "program = ignore >> many(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, '+', 10]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program.parse('20+10;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('4', ('2', ('4', ('2', '3'))))\n"
     ]
    }
   ],
   "source": [
    "import parsec as psc\n",
    "digit = psc.regex(\"[0-9]\")\n",
    "\n",
    "def number():\n",
    "  @psc.Parser\n",
    "  def number_parser(text, index):\n",
    "    res = (digit + number())(text, index)\n",
    "    return res if res.status else digit(text, index)\n",
    "  return number_parser\n",
    "\n",
    "_ = number().parse(\"42423\")\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsita import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print(1+2)\n"
     ]
    },
    {
     "ename": "ParseError",
     "evalue": "expected one of '*', '+', '-', '/', 'EOF' at 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-564aa713b6c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-564aa713b6c7>\u001b[0m in \u001b[0;36msimple_eval\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0meval_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-564aa713b6c7>\u001b[0m in \u001b[0;36meval_tokens\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mvarss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/parsy/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;34m\"\"\"Parse a string or list of tokens and return the result or raise a ParseError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0meof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/parsy/__init__.py\u001b[0m in \u001b[0;36mparse_partial\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mParseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfurthest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbind_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseError\u001b[0m: expected one of '*', '+', '-', '/', 'EOF' at 1"
     ]
    }
   ],
   "source": [
    "# Just a calculator parser\n",
    "\n",
    "from parsy import digit, generate, match_item, regex, string, success, test_item\n",
    "\n",
    "\n",
    "def lexer(code):\n",
    "    \n",
    "    whitespace = regex(r'\\s*')\n",
    "    semicolon = regex(r';')\n",
    "    integer = digit.at_least(1).concat().map(int)\n",
    "    var = regex(r'[a-zA-Z_][a-zA-Z0-9_]*')\n",
    "    float_ = (\n",
    "        digit.many() + string('.').result(['.']) + digit.many()\n",
    "    ).concat().map(float)\n",
    "    parser = whitespace >> ((\n",
    "        float_ | integer  | regex(r'[()*/+-]') | var\n",
    "    ) << whitespace).many()\n",
    "    return parser.parse(code)\n",
    "\n",
    "\n",
    "def eval_tokens(tokens):\n",
    "    # This function parses and evaluates at the same time.\n",
    "\n",
    "    lparen = match_item('(')\n",
    "    rparen = match_item(')')\n",
    "    env = {}\n",
    "    \n",
    "    \n",
    "    @generate\n",
    "    def assign():\n",
    "        res = yield varss\n",
    "        sign = match_item('=')\n",
    "        while True:\n",
    "            operation = yield sign | success('')\n",
    "            if not operation:\n",
    "                break\n",
    "                \n",
    "            operand = yield simple\n",
    "            if operation == '=':\n",
    "                env[res] = operand\n",
    "            \n",
    "\n",
    "    @generate\n",
    "    def additive():\n",
    "        res = yield multiplicative\n",
    "        sign = match_item('+') | match_item('-')\n",
    "        while True:\n",
    "            operation = yield sign | success('')\n",
    "            if not operation:\n",
    "                break\n",
    "            operand = yield multiplicative\n",
    "            if operation == '+':\n",
    "                res += operand\n",
    "            elif operation == '-':\n",
    "                res -= operand\n",
    "        return res\n",
    "\n",
    "    @generate\n",
    "    def multiplicative():\n",
    "        res = yield simple\n",
    "        op = match_item('*') | match_item('/')\n",
    "        while True:\n",
    "            operation = yield op | success('')\n",
    "            if not operation:\n",
    "                break\n",
    "            operand = yield simple\n",
    "            if operation == '*':\n",
    "                res *= operand\n",
    "            elif operation == '/':\n",
    "                res /= operand\n",
    "        return res\n",
    "\n",
    "    @generate\n",
    "    def number():\n",
    "        sign = yield match_item('+') | match_item('-') | success('+')\n",
    "        value = yield test_item(\n",
    "            lambda x: isinstance(x, (int, float)), 'number')\n",
    "        return value if sign == '+' else -value\n",
    "    \n",
    "    @generate\n",
    "    def var():\n",
    "        value = yield test_item(lambda x: isinstance(x, (str)), 'var')\n",
    "        return value\n",
    "\n",
    "    expr = additive | multiplicative | assign\n",
    "    simple = (lparen >> expr << rparen) | number | var\n",
    "    varss = var\n",
    "\n",
    "    return expr.parse(tokens)\n",
    "\n",
    "\n",
    "def simple_eval(expr):\n",
    "    return eval_tokens(lexer(expr))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(simple_eval(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Hello world'}\n"
     ]
    }
   ],
   "source": [
    "from sys import stdin\n",
    "\n",
    "from parsy import generate, regex, string\n",
    "\n",
    "whitespace = regex(r'\\s*')\n",
    "lexeme = lambda p: p << whitespace\n",
    "lbrace = lexeme(string('{'))\n",
    "rbrace = lexeme(string('}'))\n",
    "lbrack = lexeme(string('['))\n",
    "rbrack = lexeme(string(']'))\n",
    "colon  = lexeme(string(':'))\n",
    "comma  = lexeme(string(','))\n",
    "true   = lexeme(string('true')).result(True)\n",
    "false  = lexeme(string('false')).result(False)\n",
    "null   = lexeme(string('null')).result(None)\n",
    "number = lexeme(\n",
    "    regex(r'-?(0|[1-9][0-9]*)([.][0-9]+)?([eE][+-]?[0-9]+)?')\n",
    ").map(float)\n",
    "string_part = regex(r'[^\"\\\\]+')\n",
    "string_esc = string('\\\\') >> (\n",
    "    string('\\\\')\n",
    "    | string('/')\n",
    "    | string('\"')\n",
    "    | string('b').result('\\b')\n",
    "    | string('f').result('\\f')\n",
    "    | string('n').result('\\n')\n",
    "    | string('r').result('\\r')\n",
    "    | string('t').result('\\t')\n",
    "    | regex(r'u[0-9a-fA-F]{4}').map(lambda s: chr(int(s[1:], 16)))\n",
    ")\n",
    "quoted = lexeme(string('\"') >> (string_part | string_esc).many().concat() << string('\"'))\n",
    "\n",
    "\n",
    "# Circular dependency between array and value means we use `generate` form here\n",
    "@generate\n",
    "def array():\n",
    "    yield lbrack\n",
    "    elements = yield value.sep_by(comma)\n",
    "    yield rbrack\n",
    "    return elements\n",
    "\n",
    "\n",
    "@generate\n",
    "def object_pair():\n",
    "    key = yield quoted\n",
    "    yield colon\n",
    "    val = yield value\n",
    "    return (key, val)\n",
    "\n",
    "\n",
    "json_object = lbrace >> object_pair.sep_by(comma).map(dict) << rbrace\n",
    "value = quoted | number | json_object | array | true | false | null\n",
    "json = whitespace >> value\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mystr = '{\"text\" : \"Hello world\"}'\n",
    "    print(repr(json.parse(mystr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "\n",
    "class LangLexer(Lexer):\n",
    "\n",
    "    # lexer\n",
    "\n",
    "    # main tokens - ID, keywords, data types, some funcs, like TYPEOF\n",
    "\n",
    "    tokens = {ID, INT, FLOAT, ASSIGN, STRING, LET,\n",
    "              IF, ELSE, EQEQ, SEP, NOTEQ, LESS,\n",
    "              GREATER, LESSEQ, GREATEREQ, NIL, WHILE,\n",
    "              FOR, FN, RETURN, LAMBDA, ARROW, TRUE, FALSE,\n",
    "              AND, OR, SHR, SHL, INC, DEC, PLUSASGN,\n",
    "              MINUSASGN, STARASGN, SLASHASGN, MODULOASGN,\n",
    "              ANDASGN, ORASGN, XORASGN, SHLASGN, SHRASGN,\n",
    "              IMPORT, STRUCT, INT_TYPE, FLOAT_TYPE, BOOL_TYPE,\n",
    "              LIST_TYPE, DICT_TYPE, STRING_TYPE, TYPEOF,\n",
    "              LEFTARROW, PIPE, CLASS, DOUBLECOLON}\n",
    "\n",
    "    # ignore tabs and comments\n",
    "\n",
    "    ignore = ' \\t'\n",
    "    ignore_comment_slash = r'//.*'\n",
    "\n",
    "    # one-symbol literals\n",
    "\n",
    "    literals = {'=', '+', '-', '/', '*',\n",
    "                '(', ')', ',', '{', '}',\n",
    "                '%', '[', ']', '!', '&',\n",
    "                '|', '^', '?', ':', '~',\n",
    "                '.'}\n",
    "\n",
    "    # assign of logical and assign operators\n",
    "\n",
    "    INC = r'\\+\\+'\n",
    "    DEC = r'--'\n",
    "    PIPE = r'\\|>'\n",
    "    PLUSASGN = r'\\+='\n",
    "    MINUSASGN = r'-='\n",
    "    STARASGN = r'\\*='\n",
    "    SLASHASGN = r'/='\n",
    "    MODULOASGN = r'%='\n",
    "    ANDASGN = r'&='\n",
    "    ORASGN = r'\\|='\n",
    "    XORASGN = r'^='\n",
    "    SHLASGN = r'<<='\n",
    "    SHRASGN = r'>>='\n",
    "    ARROW = r'=>'\n",
    "    LESSEQ = r'<='\n",
    "    GREATEREQ = r'>='\n",
    "    LEFTARROW = r'<-'\n",
    "    SHR = r'>>'\n",
    "    SHL = r'<<'\n",
    "    LESS = r'<'\n",
    "    GREATER = r'>'\n",
    "    NOTEQ = r'!='\n",
    "    EQEQ = r'=='\n",
    "    ASSIGN = r'='\n",
    "    SEP = r';'\n",
    "    DOUBLECOLON = r'::'\n",
    "\n",
    "    # keywords\n",
    "\n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    ID['let'] = LET\n",
    "    ID['if'] = IF\n",
    "    ID['else'] = ELSE\n",
    "    ID['nil'] = NIL\n",
    "    ID['while'] = WHILE\n",
    "    ID['for'] = FOR\n",
    "    ID['fn'] = FN\n",
    "    ID['return'] = RETURN\n",
    "    ID['lambda'] = LAMBDA\n",
    "    ID['true'] = TRUE\n",
    "    ID['false'] = FALSE\n",
    "    ID['and'] = AND\n",
    "    ID['or'] = OR\n",
    "    ID['import'] = IMPORT\n",
    "    ID['struct'] = STRUCT\n",
    "    ID['int'] = INT_TYPE\n",
    "    ID['float'] = FLOAT_TYPE\n",
    "    ID['string'] = STRING_TYPE\n",
    "    ID['bool'] = BOOL_TYPE\n",
    "    ID['list'] = LIST_TYPE\n",
    "    ID['dict'] = DICT_TYPE\n",
    "    ID['typeof'] = TYPEOF\n",
    "    ID['class'] = CLASS\n",
    "\n",
    "    @_(r'\\d+\\.\\d+')\n",
    "    def FLOAT(self, t):\n",
    "        # float numbers\n",
    "        t.value = float(t.value)\n",
    "        return t\n",
    "\n",
    "    @_(r'\\d+')\n",
    "    def INT(self, t):\n",
    "        # integer numbers\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    @_(r'\\\".*?(?<!\\\\)(\\\\\\\\)*\\\"')\n",
    "    def STRING(self, t):\n",
    "        # parsing the string type and cleaning it\n",
    "        t.value = t.value[1:-1]\n",
    "        t.value = t.value.replace(r\"\\n\", \"\\n\")\n",
    "        t.value = t.value.replace(r\"\\t\", \"\\t\")\n",
    "        t.value = t.value.replace(r\"\\\\\", \"\\\\\")\n",
    "        t.value = t.value.replace(r\"\\\"\", \"\\\"\")\n",
    "        t.value = t.value.replace(r\"\\a\", \"\\a\")\n",
    "        t.value = t.value.replace(r\"\\b\", \"\\b\")\n",
    "        t.value = t.value.replace(r\"\\r\", \"\\r\")\n",
    "        t.value = t.value.replace(r\"\\t\", \"\\t\")\n",
    "        t.value = t.value.replace(r\"\\v\", \"\\v\")\n",
    "        return t\n",
    "\n",
    "    @_(r'\\n+')\n",
    "    def ignore_newline(self, t):\n",
    "        self.lineno += len(t.value)\n",
    "\n",
    "    def error(self, t):\n",
    "        print(\"Illegal character '%s' on line %d\" % (t.value[0], self.lineno))\n",
    "        self.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 2\n",
      "[1, '+', 2]\n",
      "<parsy.Parser object at 0x7f1cf1ebac50>\n",
      "('+', None, None)\n"
     ]
    }
   ],
   "source": [
    "from parsy import digit, generate, match_item, regex, string, success, test_item\n",
    "\n",
    "\n",
    "def lexer(code):\n",
    "    whitespace = regex(r'\\s*')\n",
    "    semicolon = regex(r';')\n",
    "    integer = digit.at_least(1).concat().map(int)\n",
    "    float_ = (\n",
    "        digit.many() + string('.').result(['.']) + digit.many()\n",
    "    ).concat().map(float)\n",
    "    parser = whitespace >> ((\n",
    "        float_ | integer  | regex(r'[()*/+-]')\n",
    "    ) << whitespace).many()\n",
    "    return parser.parse(code)\n",
    "\n",
    "\n",
    "def eval_tokens(tokens):\n",
    "    # This function parses and evaluates at the same time.\n",
    "\n",
    "    lparen = match_item('(')\n",
    "    rparen = match_item(')')\n",
    "\n",
    "    @generate\n",
    "    def additive():\n",
    "        res = yield multiplicative\n",
    "        print(multiplicative)\n",
    "        sign = match_item('+') | match_item('-')\n",
    "        while True:\n",
    "            operation = yield sign | success('')\n",
    "            if not operation:\n",
    "                break\n",
    "            operand = yield multiplicative\n",
    "            if operation == '+':\n",
    "                return ('+', res, operand)\n",
    "            elif operation == '-':\n",
    "                return ('-', res, operand)\n",
    "\n",
    "    @generate\n",
    "    def multiplicative():\n",
    "        res = yield simple\n",
    "        op = match_item('*') | match_item('/')\n",
    "        while True:\n",
    "            operation = yield op | success('')\n",
    "            if not operation:\n",
    "                break\n",
    "            operand = yield simple\n",
    "            if operation == '*':\n",
    "                return ('*', res, operand)\n",
    "            elif operation == '-':\n",
    "                return ('/', res, operand)\n",
    "\n",
    "    @generate\n",
    "    def number():\n",
    "        sign = yield match_item('+') | match_item('-') | success('+')\n",
    "        value = yield test_item(\n",
    "            lambda x: isinstance(x, (int, float)), 'number')\n",
    "        return value if sign == '+' else -value\n",
    "\n",
    "    expr = additive\n",
    "    simple = (lparen >> expr << rparen) | number\n",
    "\n",
    "    return expr.parse(tokens)\n",
    "\n",
    "\n",
    "def simple_eval(expr):\n",
    "    print(lexer(expr))\n",
    "    return eval_tokens(lexer(expr))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(simple_eval(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 2, '-', 3, ')', '*', 14, ';']\n"
     ]
    }
   ],
   "source": [
    "lex = LangLexer()\n",
    "expr = \"(2-3)*14;\"\n",
    "\n",
    "toks = lex.tokenize(expr)\n",
    "\n",
    "class CombParser:\n",
    "    def parse_input_tokens(self,tokens):\n",
    "        list_of_tokens = [tok.value for tok in tokens]\n",
    "        print(list_of_tokens)\n",
    "    \n",
    "a = CombParser()\n",
    "a.parse_input_tokens(toks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
